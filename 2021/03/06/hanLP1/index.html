<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="使用hanLP进行自定义NER训练"><meta name="keywords" content="tensorflow,人工智能,NLP"><meta name="author" content="Lacus Rinz"><meta name="copyright" content="Lacus Rinz"><title>使用hanLP进行自定义NER训练 | Rinz's Blog</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.7.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.7.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  }
} </script><meta name="generator" content="Hexo 4.2.0"></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="切换文章详情">切换站点概览</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#目的"><span class="toc-number">1.</span> <span class="toc-text"> 目的</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#环境"><span class="toc-number">2.</span> <span class="toc-text"> 环境</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#准备数据标注"><span class="toc-number">3.</span> <span class="toc-text"> 准备数据标注</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#转化标注数据集格式"><span class="toc-number">4.</span> <span class="toc-text"> 转化标注数据集格式</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#开始训练"><span class="toc-number">5.</span> <span class="toc-text"> 开始训练</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/images/avatar.JPG"></div><div class="author-info__name text-center">Lacus Rinz</div><div class="author-info__description text-center"></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">14</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">标签</span><span class="pull-right">14</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">分类</span><span class="pull-right">2</span></a></div></div></div><div id="content-outer"><div class="no-bg" id="top-container"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Rinz's Blog</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span><span class="pull-right"></span></div><div id="post-info"><div id="post-title">使用hanLP进行自定义NER训练</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2021-03-06</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BA%94%E7%94%A8/">机器学习应用</a></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><h1 id="目的"><a class="markdownIt-Anchor" href="#目的"></a> 目的</h1>
<p>为了将非结构化的简历文本提取出有效的工作经历信息，尝试使用各类NLP框架进行文本实体识别，目标是分解出时间，工作地点，任职单位，职务等有效信息。</p>
<p>在尝试了一些分词和NLP框架后，选用<a href="https://github.com/hankcs/HanLP" target="_blank" rel="noopener">hanLP</a>作为训练工具，在自己制作的数据集（人物简历信息）上训练自定义的NER标签（职务），实现特定标签的文本实体识别。</p>
<a id="more"></a>
<h1 id="环境"><a class="markdownIt-Anchor" href="#环境"></a> 环境</h1>
<p>tensorflow 2.x</p>
<p>Colaboratory with GPU</p>
<p>hanLP 2.1</p>
<h1 id="准备数据标注"><a class="markdownIt-Anchor" href="#准备数据标注"></a> 准备数据标注</h1>
<p>要制作自定义数据集，就离不开标注工具，这里选用著名的开源标注工具<a href="https://github.com/doccano/doccano" target="_blank" rel="noopener">doccano</a></p>
<p>在服务器部署好doccano，导入数据</p>
<p><img src="1.png" alt="图片" /></p>
<p>添加标签</p>
<p><img src="2.png" alt="图片" /></p>
<p>开始标注</p>
<p><img src="3.png" alt="图片" /></p>
<p>标注完成后导出数据</p>
<p><img src="4.png" alt="图片" /></p>
<p>注意这里选择第二种格式，这种格式会带着你的标签名字一起导出。</p>
<h1 id="转化标注数据集格式"><a class="markdownIt-Anchor" href="#转化标注数据集格式"></a> 转化标注数据集格式</h1>
<p>上面导出的JSONL数据并不能直接作为训练集放入NLP框架中训练，通用的训练集一般都使用BIO，BIOES，BMES标注</p>
<blockquote>
<p>一、BMES  四位序列标注法<br />
B表示一个词的词首位值，M表示一个词的中间位置，E表示一个词的末尾位置，S表示一个单独的字词。<br />
二、BIO三位标注  (B-begin，I-inside，O-outside)<br />
B-X 代表实体X的开头，I-X代表实体的结尾O代表不属于任何类型的<br />
三、BIOES (B-begin，I-inside，O-outside，E-end，S-single)<br />
B 表示开始，I表示内部， O表示非实体 ，E实体尾部，S表示改词本身就是一个实体。</p>
</blockquote>
<blockquote>
<p>示例：<br />
因 O<br />
有 O<br />
关 O<br />
日 S-NS<br />
寇 O<br />
在 O<br />
京 S-NS<br />
掠 O<br />
夺 O<br />
文 O<br />
物 O<br />
详 O<br />
情 O<br />
， O<br />
藏 O<br />
界 O<br />
较 O<br />
为 O<br />
重 O<br />
视 O<br />
， O<br />
也 O<br />
是 O<br />
我 O<br />
们 O<br />
收 O<br />
藏 O<br />
北 B-NS<br />
京 E-NS<br />
史 O<br />
料 O<br />
中 O<br />
的 O<br />
要 O<br />
件 O<br />
之 O<br />
一 O<br />
。 O</p>
</blockquote>
<p>同时NER训练集一般有“CoNLL 2003” “MSRA”两种dataset形式，doccano为我们提供了doccano-transformer这个转化工具，由于该工具面向是英文文本，所以在转化中文文本是有一些小问题，这里我fork了一份doccano-transformer并进行了修正，可以下载我的这份<a href="https://github.com/lacusrinz/doccano-transformer" target="_blank" rel="noopener">代码</a></p>
<p>使用</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> doccano_transformer.datasets <span class="keyword">import</span> NERDataset</span><br><span class="line"><span class="keyword">from</span> doccano_transformer.utils <span class="keyword">import</span> read_jsonl</span><br><span class="line">dataset = read_jsonl(filepath=<span class="string">'example.jsonl'</span>, dataset=NERDataset, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">dataset.to_conll2003(tokenizer=str.split)</span><br><span class="line">这里注意to_conll2003(tokenizer)方法的参数tokenizer是一个文本分割方法，当传入的是str.split则是将string使用所有的空字符，包括空格、换行(\n)、制表符(\t)等进行分割。这种分割方式对英文句子里每个英文单词使用空字符分割的情况完美适配，但是含有中文文本的句子如果按照这种方式，连续的汉字无法被分割，导致无法正常标注。</span><br></pre></td></tr></table></figure>
<p>所以我们需要编写能将文本中的数字英文按空字符分割，中文按汉字分割的方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_word_list</span><span class="params">(s1)</span>:</span></span><br><span class="line">    <span class="comment"># 把句子按字分开，中文按字分，英文按单词，数字按空格</span></span><br><span class="line">    res = re.compile(<span class="string">r"([\u4e00-\u9fa5])"</span>)    <span class="comment">#  [\u4e00-\u9fa5]中文范围</span></span><br><span class="line">    p1 = res.split(s1)</span><br><span class="line">    <span class="comment"># print(p1)</span></span><br><span class="line">    str1_list = []</span><br><span class="line">    <span class="keyword">for</span> str <span class="keyword">in</span> p1:</span><br><span class="line">        <span class="keyword">if</span> res.split(str) == <span class="literal">None</span>:</span><br><span class="line">            str1_list.append(str)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            ret = res.split(str)</span><br><span class="line">            <span class="keyword">for</span> ch <span class="keyword">in</span> ret:</span><br><span class="line">                str1_list.append(ch)</span><br><span class="line">    list_words = [w <span class="keyword">for</span> w <span class="keyword">in</span> str1_list <span class="keyword">if</span> len(w.strip()) &gt; <span class="number">0</span>]  <span class="comment"># 去掉为空的字符</span></span><br><span class="line">    lists=[]</span><br><span class="line">    <span class="keyword">for</span> list_word <span class="keyword">in</span> list_words:</span><br><span class="line">      splits = list_word.split()</span><br><span class="line">      <span class="comment"># print(split)</span></span><br><span class="line">      <span class="keyword">for</span> split <span class="keyword">in</span> splits:</span><br><span class="line">        lists.append(split)</span><br><span class="line">    <span class="keyword">return</span>  lists</span><br></pre></td></tr></table></figure>
<p>应用</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataset &#x3D; dataset.to_conll2003(tokenizer&#x3D;get_word_list)</span><br></pre></td></tr></table></figure>
<p>然后将dataset输出成tsv，即完成了训练集的制作。</p>
<h1 id="开始训练"><a class="markdownIt-Anchor" href="#开始训练"></a> 开始训练</h1>
<p>参考hanLP的文档，训练就非常简单了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> hanlp</span><br><span class="line"><span class="keyword">from</span> hanlp.components.ner_tf <span class="keyword">import</span> TransformerNamedEntityRecognizerTF</span><br><span class="line">recognizer = TransformerNamedEntityRecognizerTF()</span><br><span class="line">save_dir = <span class="string">'data/model/ner/finetune_ner_albert_base_zh_msra'</span></span><br><span class="line">CONLL03_RESUME_TRAIN=<span class="string">"Output_train.tsv"</span></span><br><span class="line">CONLL03_RESUME_TEST=<span class="string">"Output_test.tsv"</span></span><br><span class="line">recognizer.fit(CONLL03_RESUME_TRAIN, CONLL03_RESUME_TEST, save_dir, epochs=<span class="number">20</span>, transformer=<span class="string">'albert_base_zh'</span>,</span><br><span class="line">               finetune=hanlp.pretrained.ner.MSRA_NER_ALBERT_BASE_ZH)</span><br><span class="line">recognizer.load(save_dir)</span><br><span class="line">print(recognizer.predict(list(<span class="string">'2020年6月23日上午，吴江区第十六届人大常委会第二十九次会议召开，审议和通过有关人事任免，同意李铭同志因工作变动辞去吴江区区长职务'</span>)))</span><br><span class="line"><span class="comment"># recognizer.evaluate(CONLL03_RESUME_TEST, save_dir=save_dir)</span></span><br><span class="line">print(<span class="string">f'Model saved in <span class="subst">&#123;save_dir&#125;</span>'</span>)</span><br></pre></td></tr></table></figure>
<p>这里使用MSRA_NER_ALBERT_BASE_ZH预训练模型进行finetune操作，训练结果如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line">2021-03-04 10:18:23 INFO Hyperparameter:</span><br><span class="line">&#123;</span><br><span class="line">  &quot;batch_size&quot;: 32,</span><br><span class="line">  &quot;epochs&quot;: 20,</span><br><span class="line">  &quot;run_eagerly&quot;: false,</span><br><span class="line">  &quot;finetune&quot;: &quot;https:&#x2F;&#x2F;file.hankcs.com&#x2F;hanlp&#x2F;ner&#x2F;ner_albert_base_zh_msra_20200111_202919.zip&quot;,</span><br><span class="line">  &quot;transformer&quot;: &quot;albert_base_zh&quot;,</span><br><span class="line">  &quot;optimizer&quot;: &quot;adamw&quot;,</span><br><span class="line">  &quot;learning_rate&quot;: 5e-05,</span><br><span class="line">  &quot;weight_decay_rate&quot;: 0,</span><br><span class="line">  &quot;epsilon&quot;: 1e-08,</span><br><span class="line">  &quot;clipnorm&quot;: 1.0,</span><br><span class="line">  &quot;warmup_steps_ratio&quot;: 0,</span><br><span class="line">  &quot;use_amp&quot;: false,</span><br><span class="line">  &quot;max_seq_length&quot;: 128,</span><br><span class="line">  &quot;metrics&quot;: &quot;f1&quot;</span><br><span class="line">&#125;</span><br><span class="line">2021-03-04 10:18:23 INFO Vocab summary:</span><br><span class="line">tag_vocab[4] &#x3D; [&#39;&lt;pad&gt;&#39;, &#39;O&#39;, &#39;B-job&#39;, &#39;I-job&#39;]</span><br><span class="line">2021-03-04 10:18:23 INFO Building...</span><br><span class="line">2021-03-04 10:18:25 INFO Model built:</span><br><span class="line">Model: &quot;model_4&quot;</span><br><span class="line">__________________________________________________________________________________________________</span><br><span class="line">Layer (type)                    Output Shape         Param #     Connected to                     </span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">input_ids (InputLayer)          [(None, 128)]        0                                            </span><br><span class="line">__________________________________________________________________________________________________</span><br><span class="line">token_type_ids (InputLayer)     [(None, 128)]        0                                            </span><br><span class="line">__________________________________________________________________________________________________</span><br><span class="line">mask_ids (InputLayer)           [(None, 128)]        0                                            </span><br><span class="line">__________________________________________________________________________________________________</span><br><span class="line">albert (BertModelLayer)         (None, 128, 768)     9957376     input_ids[0][0]                  </span><br><span class="line">                                                                 token_type_ids[0][0]             </span><br><span class="line">                                                                 mask_ids[0][0]                   </span><br><span class="line">__________________________________________________________________________________________________</span><br><span class="line">dense_4 (Dense)                 (None, 128, 4)       3076        albert[0][0]                     </span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">Total params: 9,960,452</span><br><span class="line">Trainable params: 9,960,452</span><br><span class="line">Non-trainable params: 0</span><br><span class="line">__________________________________________________________________________________________________</span><br><span class="line">2021-03-04 10:18:25 INFO Loaded pretrained weights from &#x2F;root&#x2F;.hanlp&#x2F;ner&#x2F;ner_albert_base_zh_msra_20200111_202919&#x2F;model.h5 for finetuning</span><br><span class="line">Epoch 1&#x2F;20</span><br><span class="line">15&#x2F;15 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 70s 5s&#x2F;step - loss: 13.7708 - f1: 0.0012 - val_loss: 2.4522 - val_f1: 0.0946</span><br><span class="line">Epoch 2&#x2F;20</span><br><span class="line">15&#x2F;15 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 69s 5s&#x2F;step - loss: 2.0932 - f1: 0.1956 - val_loss: 1.2397 - val_f1: 0.4171</span><br><span class="line">Epoch 3&#x2F;20</span><br><span class="line">15&#x2F;15 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 69s 5s&#x2F;step - loss: 1.0135 - f1: 0.3879 - val_loss: 0.9292 - val_f1: 0.4541</span><br><span class="line">Epoch 4&#x2F;20</span><br><span class="line">15&#x2F;15 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 68s 5s&#x2F;step - loss: 0.7765 - f1: 0.3948 - val_loss: 1.0566 - val_f1: 0.4069</span><br><span class="line">Epoch 5&#x2F;20</span><br><span class="line">15&#x2F;15 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 69s 5s&#x2F;step - loss: 0.6658 - f1: 0.4120 - val_loss: 0.5538 - val_f1: 0.5824</span><br><span class="line">Epoch 6&#x2F;20</span><br><span class="line">15&#x2F;15 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 68s 5s&#x2F;step - loss: 0.6176 - f1: 0.5337 - val_loss: 0.4626 - val_f1: 0.5601</span><br><span class="line">Epoch 7&#x2F;20</span><br><span class="line">15&#x2F;15 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 68s 5s&#x2F;step - loss: 0.6748 - f1: 0.4999 - val_loss: 0.4283 - val_f1: 0.6131</span><br><span class="line">Epoch 8&#x2F;20</span><br><span class="line">15&#x2F;15 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 68s 5s&#x2F;step - loss: 0.3727 - f1: 0.6239 - val_loss: 0.3824 - val_f1: 0.6786</span><br><span class="line">Epoch 9&#x2F;20</span><br><span class="line">15&#x2F;15 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 68s 5s&#x2F;step - loss: 0.5163 - f1: 0.6342 - val_loss: 0.2894 - val_f1: 0.6708</span><br><span class="line">Epoch 10&#x2F;20</span><br><span class="line">15&#x2F;15 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 67s 5s&#x2F;step - loss: 0.2572 - f1: 0.6855 - val_loss: 0.3856 - val_f1: 0.6812</span><br><span class="line">Epoch 11&#x2F;20</span><br><span class="line">15&#x2F;15 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 67s 5s&#x2F;step - loss: 0.3237 - f1: 0.6667 - val_loss: 0.2107 - val_f1: 0.7319</span><br><span class="line">Epoch 12&#x2F;20</span><br><span class="line">15&#x2F;15 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 68s 5s&#x2F;step - loss: 0.2778 - f1: 0.7104 - val_loss: 0.2025 - val_f1: 0.7081</span><br><span class="line">Epoch 13&#x2F;20</span><br><span class="line">15&#x2F;15 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 66s 5s&#x2F;step - loss: 0.1871 - f1: 0.7224 - val_loss: 0.1639 - val_f1: 0.8040</span><br><span class="line">Epoch 14&#x2F;20</span><br><span class="line">15&#x2F;15 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 67s 5s&#x2F;step - loss: 0.1868 - f1: 0.7405 - val_loss: 0.1240 - val_f1: 0.8250</span><br><span class="line">Epoch 15&#x2F;20</span><br><span class="line">15&#x2F;15 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 67s 5s&#x2F;step - loss: 0.1251 - f1: 0.7685 - val_loss: 0.1278 - val_f1: 0.8143</span><br><span class="line">Epoch 16&#x2F;20</span><br><span class="line">15&#x2F;15 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 66s 5s&#x2F;step - loss: 0.1123 - f1: 0.8196 - val_loss: 0.0957 - val_f1: 0.8591</span><br><span class="line">Epoch 17&#x2F;20</span><br><span class="line">15&#x2F;15 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 67s 5s&#x2F;step - loss: 0.1021 - f1: 0.8548 - val_loss: 0.0814 - val_f1: 0.8973</span><br><span class="line">Epoch 18&#x2F;20</span><br><span class="line">15&#x2F;15 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 66s 5s&#x2F;step - loss: 0.0803 - f1: 0.8640 - val_loss: 0.0737 - val_f1: 0.8945</span><br><span class="line">Epoch 19&#x2F;20</span><br><span class="line">15&#x2F;15 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 67s 5s&#x2F;step - loss: 0.0879 - f1: 0.8620 - val_loss: 0.0679 - val_f1: 0.9035</span><br><span class="line">Epoch 20&#x2F;20</span><br><span class="line">15&#x2F;15 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 67s 5s&#x2F;step - loss: 0.0670 - f1: 0.9267 - val_loss: 0.0639 - val_f1: 0.9114</span><br><span class="line">2021-03-04 10:40:57 INFO Trained 20 epochs in 22 m 32 s, each epoch takes 1 m 8 s</span><br><span class="line">[(&#39;6&#39;, &#39;ad&gt;&#39;, 5, 6), (&#39;日上午&#39;, &#39;job&#39;, 9, 12), (&#39;吴江区第十&#39;, &#39;job&#39;, 13, 18), (&#39;大&#39;, &#39;job&#39;, 21, 22), (&#39;会&#39;, &#39;job&#39;, 30, 31)]</span><br><span class="line">Model saved in data&#x2F;model&#x2F;ner&#x2F;finetune_ner_albert_base_zh_msra</span><br></pre></td></tr></table></figure>
<p>训练过程没有问题，但是训练出来的模型效果一般，问题可能出在训练集数据太少，后面会做进一步探索。</p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Lacus Rinz</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://lacusrinz.github.com/2021/03/06/hanLP1/">http://lacusrinz.github.com/2021/03/06/hanLP1/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://lacusrinz.github.com">Rinz's Blog</a>！</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/tensorflow/">tensorflow</a><a class="post-meta__tags" href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a><a class="post-meta__tags" href="/tags/NLP/">NLP</a></div><div class="post-qr-code"><div class="post-qr-code-item"><img class="post-qr-code__img" src="/images/alipay.jpg"><div class="post-qr-code__desc">支付宝打赏</div></div><div class="post-qr-code-item"><img class="post-qr-code__img" src="/images/wechat.jpg"><div class="post-qr-code__desc">微信打赏</div></div></div><nav id="pagination"><div class="next-post pull-right"><a href="/2020/11/22/object-detection-API%E8%BF%81%E7%A7%BB%E5%88%B0tf2/"><span>object detection API迁移到tf2</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2013 - 2021 By Lacus Rinz</div><div class="framework-info"><span>驱动 - </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody" target="_blank" rel="noopener"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.7.0"></script><script src="/js/fancybox.js?version=1.7.0"></script><script src="/js/sidebar.js?version=1.7.0"></script><script src="/js/copy.js?version=1.7.0"></script><script src="/js/fireworks.js?version=1.7.0"></script><script src="/js/transition.js?version=1.7.0"></script><script src="/js/scroll.js?version=1.7.0"></script><script src="/js/head.js?version=1.7.0"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script src="/js/katex.js"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script></body></html>